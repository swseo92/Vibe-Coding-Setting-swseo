# AI Debate v4.0: Implementation Plan

**Executive Summary Document**

**Version**: 4.0.0-implementation-plan
**Date**: 2025-11-04
**Status**: âœ… Ready for Implementation
**Based on**: Design doc + Codex debate results

---

## 1. Final Decisions (ë¯¸í•´ê²° ì§ˆë¬¸ í•´ê²°ë¨)

### Q1: Devil's Advocate Mode â†’ v4.1ë¡œ ì—°ê¸°

**Decision**: â³ **NOT in v4.0**, defer to v4.1+

**Reasoning (from debate)**:
- Codex: ì‹ ë¢°ë„ ì‹ í˜¸ ê¸°ë°˜ ìë™ í™œì„±í™” ì œì•ˆ
- Main Claude: ì‚¬ìš©ì ëª…ì‹œì  í”Œë˜ê·¸ ì œì•ˆ
- **í•©ì˜**: í•˜ì´ë¸Œë¦¬ë“œ (ìë™ ê°ì§€ + ìˆ˜ë™ í”Œë˜ê·¸)
- **But**: ì‹ ë¢°ë„ ì‹ í˜¸ ì‹œìŠ¤í…œì´ ì•„ì§ ì—†ìŒ â†’ v4.1ì—ì„œ êµ¬í˜„

**v4.0 Action**: Skip (êµ¬í˜„ ì•ˆ í•¨)
**v4.1 Plan**:
```python
if confidence_variance > 0.3 or user_flag == "--devil-advocate":
    activate_devils_advocate()
```

---

### Q2: Unanimous Agreement â†’ Codex ë°©ì‹ ì±„íƒ âœ…

**Decision**: âœ… **Implement Codex's Self-Review Approach**

**What to implement**:
```python
if unanimous_agreement(threshold=90%):
    # Step 1: Lightweight safety check (2-3s overhead)
    review = {
        "claude_failure_mode": "Most likely failure: [20 words max]",
        "codex_failure_mode": "Most likely failure: [20 words max]"
    }

    # Step 2: Auto-decision
    if high_risk_flagged(review):
        run_full_debate()  # Phase 3-4
    else:
        skip_to_synthesis()  # Phase 6
        # Show: "[âœ… Both agents agree. View reasoning?]"
```

**Why Codex wins**:
- ì‚¬ìš©ì ì¸í„°ë™ì…˜ 0ì´ˆ (vs My: 10-30s ëŒ€ê¸°)
- Failure mode ì²´í¬ë¡œ ì•ˆì „ì¥ì¹˜ í™•ë³´
- íˆ¬ëª…ì„±: "View reasoning" ë§í¬ë¡œ ìœ ì§€

**Implementation time**: 2-3 hours

---

### Q3: Maximum Rounds â†’ Main Claude ë°©ì‹ ì±„íƒ âœ…

**Decision**: âœ… **User-Triggered Extension (My Approach)**

**What to implement**:
```python
DEFAULT_MAX_ROUNDS = 3  # Fixed
ABSOLUTE_CAP = 5        # Hard limit

# Phase 5: User intervention point
options = [
    "Deep dive on [topic]",      # +1 round for specific topic
    "Add new constraint",          # Restart with new info
    "Conclude"                     # Skip to Phase 6
]

if user_selects("Deep dive"):
    max_rounds = 4
    show_eta("+30s for focused analysis")
```

**Why My approach wins**:
- Codex ì‹ í˜¸ ê¸°ë°˜ ìë™ í™•ì¥ì€ ì‹ í˜¸ í’ˆì§ˆ ê²€ì¦ í•„ìš” (v4.2+)
- User-triggeredëŠ” ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥í•˜ê³  ì•ˆì „
- Phase 5 ì´ë¯¸ ê°œì…ì ì´ë¯€ë¡œ ìì—°ìŠ¤ëŸ¬ì›€

**Implementation time**: 1-2 hours (Phase 5 êµ¬í˜„ ì¼ë¶€)

---

## 2. v4.0 Final Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: Pre-Clarification (ê¸°ì¡´ ìœ ì§€)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: Round 1 - Independent Analysis                 â”‚
â”‚ â”œâ”€ 2.1: Main Claude opinion (0.7s)                      â”‚
â”‚ â”œâ”€ 2.2: Codex opinion (19s)                            â”‚
â”‚ â””â”€ 2.3: Unanimous check (NEW)                          â”‚
â”‚        if unanimous â†’ Self-review (2s)                  â”‚
â”‚           if safe â†’ SKIP to Phase 6                    â”‚
â”‚           if risky â†’ Continue to Phase 3               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: Round 2 - Constructive Challenge               â”‚
â”‚ â”œâ”€ 3.1: Main Claude â†’ Codex challenge (15s)            â”‚
â”‚ â”‚      âœ… Strengths âš ï¸ Questions âŒ Weak spots ğŸ“Š Evidence â”‚
â”‚ â”œâ”€ 3.2: Codex â†’ Main Claude challenge (15s) [parallel] â”‚
â”‚ â””â”€ Total: 30s (parallel execution)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 4: Round 3 - Evidence & Refinement                â”‚
â”‚ â”œâ”€ 4.1: Main Claude responds + WebSearch (20s)         â”‚
â”‚ â”œâ”€ 4.2: Codex responds + WebSearch (20s) [parallel]    â”‚
â”‚ â””â”€ Total: 20-50s (depends on evidence complexity)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 5: User Intervention Point (NEW)                  â”‚
â”‚ â”œâ”€ Show debate summary                                  â”‚
â”‚ â”œâ”€ Options:                                             â”‚
â”‚ â”‚   1. Deep dive on [topic] â†’ Loop to Phase 3 (+1 round)â”‚
â”‚ â”‚   2. Add constraint â†’ Restart Phase 2                â”‚
â”‚ â”‚   3. Conclude â†’ Phase 6                              â”‚
â”‚ â””â”€ [10-30s user think time]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 6: Final Synthesis                                 â”‚
â”‚ â”œâ”€ Integrate all rounds                                 â”‚
â”‚ â”œâ”€ Re-evaluate confidence                               â”‚
â”‚ â””â”€ Present refined recommendation (2s)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Performance Budget**:
| Path | Time | Scenario |
|------|------|----------|
| **Fast path** (unanimous) | 28s | ëª…í™•í•œ ì¼€ì´ìŠ¤ (Phase 6 ì§í–‰) |
| **Normal path** | 56-86s | ì¼ë°˜ í† ë¡  (Phase 2â†’6) |
| **Deep dive** | 86-120s | ì‚¬ìš©ì ì‹¬í™” ìš”ì²­ (+1 round) |

---

## 3. Implementation Roadmap

### Week 1: Core Implementation (6-8 hours)

#### Day 1-2: Phase 3 (Constructive Challenge)

**Tasks**:
1. âœ… skill.mdì— Phase 3 ì„¹ì…˜ ì¶”ê°€
2. âœ… Challenge í…œí”Œë¦¿ ì‘ì„± (âœ…âš ï¸âŒğŸ“Š êµ¬ì¡°)
3. âœ… Main Claude â†’ Codex challenge ë¡œì§
4. âœ… Codex â†’ Main Claude challenge (codex-session.sh)
5. âœ… ë³‘ë ¬ ì‹¤í–‰ êµ¬í˜„

**Deliverables**:
```markdown
# In skill.md

### Phase 3: Constructive Challenge

#### 3.1 Main Claude Challenges Codex
[Template with guidelines]

#### 3.2 Codex Challenges Main Claude
[codex-session.sh command]
```

**Test**:
```bash
# tmp/test-phase3.sh
bash test-constructive-challenge.sh "Django vs FastAPI"
# Expected: Two challenge outputs in âœ…âš ï¸âŒğŸ“Š format
```

**Time**: 3-4 hours

---

#### Day 2-3: Phase 4 (Evidence & Refinement)

**Tasks**:
1. âœ… skill.mdì— Phase 4 ì„¹ì…˜ ì¶”ê°€
2. âœ… ì‘ë‹µ í…œí”Œë¦¿ ì‘ì„±
3. âœ… WebSearch í†µí•© ê°ì§€ ë¡œì§
4. âœ… Evidence í¬ë§·íŒ… í…œí”Œë¦¿
5. âœ… "No evidence found" í´ë°±

**Deliverables**:
```markdown
# In skill.md

### Phase 4: Evidence-Based Refinement

#### 4.1 Main Claude Responds
[Response template with evidence integration]

#### 4.2 Codex Responds
[codex-session.sh continue command]
```

**WebSearch Integration**:
```python
# Pseudo-code in skill.md instructions
if "ğŸ“Š Evidence Requested:" in challenge:
    query = extract_query(challenge)
    results = WebSearch(query)
    evidence = format_results(results)
```

**Test**:
```bash
# tmp/test-phase4.sh
bash test-evidence-refinement.sh "FastAPI performance benchmark"
# Expected: Response with WebSearch results cited
```

**Time**: 3-4 hours

---

### Week 2: User Features & Polish (6-8 hours)

#### Day 4-5: Phase 5 (User Intervention)

**Tasks**:
1. âœ… Debate summary í…œí”Œë¦¿ ì‘ì„±
2. âœ… AskUserQuestion í†µí•© (3 options)
3. âœ… Loop-back ë¡œì§ (deep dive â†’ Phase 3)
4. âœ… Constraint injection (add info â†’ Phase 2)
5. âœ… "Conclude" path (â†’ Phase 6)

**Deliverables**:
```markdown
# In skill.md

### Phase 5: User Intervention Point

#### 5.1 Present Debate Summary
[Summary template]

#### 5.2 Handle User Input
[AskUserQuestion implementation]
[Loop-back logic]
```

**AskUserQuestion Example**:
```json
{
  "questions": [{
    "question": "What would you like to do next?",
    "header": "Next Step",
    "multiSelect": false,
    "options": [
      {"label": "Deep dive: [topic]", "description": "+30s for focused analysis"},
      {"label": "Add constraint", "description": "Introduce new information"},
      {"label": "Conclude", "description": "Proceed to final synthesis"}
    ]
  }]
}
```

**Test**:
```bash
# tmp/test-phase5.sh
bash test-user-intervention.sh
# Interactive: user selects option, flow continues correctly
```

**Time**: 3-4 hours

---

#### Day 5-6: Phase 2.3 (Unanimous Check) + Phase 6 Update

**Tasks**:
1. âœ… Phase 2.3 ì¶”ê°€: Unanimous agreement detection
2. âœ… Self-review prompt (20 words max)
3. âœ… Risk detection logic
4. âœ… Phase 6 ì—…ë°ì´íŠ¸: Multi-round synthesis
5. âœ… Confidence re-evaluation logic

**Deliverables**:
```markdown
# In skill.md

### Phase 2.3: Unanimous Agreement Check (NEW)
[Detection logic]
[Self-review template]
[Decision tree: skip vs continue]

### Phase 6: Final Synthesis (UPDATED)
[Multi-round synthesis template]
[Confidence evolution tracking]
```

**Self-Review Template**:
```
Task: Identify the most likely failure mode of your recommendation in â‰¤20 words.

Example:
"Most likely failure: Team lacks async expertise, FastAPI learning curve exceeds 3-month timeline."
```

**Test**:
```bash
# tmp/test-unanimous.sh
bash test-unanimous-handling.sh "Python 3.12 vs 3.11?"
# Expected: Self-review â†’ auto-skip to Phase 6 (if safe)
```

**Time**: 2-3 hours

---

#### Day 6-7: Testing & Refinement

**Tasks**:
1. âœ… End-to-end test (3 scenarios)
2. âœ… Performance measurement
3. âœ… Edge case handling
4. âœ… Documentation polish
5. âœ… Examples update

**Test Scenarios**:

**Scenario 1: Fast path (unanimous)**
```
Input: "Should I use Python 3.12 over 3.11?"
Expected: 28s total (Phase 2 â†’ self-review â†’ Phase 6)
```

**Scenario 2: Normal debate**
```
Input: "Django vs FastAPI (5 devs, 10k users, 3 months)"
Expected: 56-86s (Phase 2 â†’ 3 â†’ 4 â†’ 5 [conclude] â†’ 6)
```

**Scenario 3: Deep dive**
```
Input: Same as Scenario 2
User action: "Deep dive on team skillset"
Expected: 86-120s (Phase 2 â†’ 3 â†’ 4 â†’ 5 [deep dive] â†’ 3 â†’ 4 â†’ 6)
```

**Performance Validation**:
```bash
# tmp/test-performance.sh
for i in {1..5}; do
  time bash test-ai-debate-v4.sh "Test question $i"
done
# Target: avg <90s for normal path
```

**Time**: 2-3 hours

---

### Week 2 End: Deployment (1 hour)

**Tasks**:
1. âœ… Git commit all changes
2. âœ… Update version to 4.0.0-complete
3. âœ… `/apply-settings` to global
4. âœ… Verify in test project
5. âœ… Update CHANGELOG.md

**Commit Message**:
```bash
git commit -m "feat(ai-debate): Implement v4.0 Progressive Constructive Debate

Major features:
- Phase 3: Constructive Challenge (âœ…âš ï¸âŒğŸ“Š format)
- Phase 4: Evidence-Based Refinement (WebSearch integration)
- Phase 5: User Intervention Point (deep dive, add constraint, conclude)
- Phase 2.3: Unanimous Agreement Check (self-review + smart skip)
- Phase 6: Multi-round synthesis with confidence evolution

Performance:
- Fast path: 28s (unanimous cases)
- Normal path: 56-86s (full debate)
- Deep dive: 86-120s (user-requested extension)

Breaking changes: None (v3.1 still works, v4.0 is opt-in via trigger)

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

**Verification**:
```bash
cd ~/other-project
claude
> AI í† ë¡ : Redis vs Memcached?
# Expected: v4.0 workflow executes successfully
```

**Time**: 1 hour

---

## 4. What NOT to Do (v4.0 Scope Control)

### âŒ Out of Scope for v4.0

**1. Devil's Advocate Mode**
- Reason: ì‹ ë¢°ë„ ì‹ í˜¸ ì‹œìŠ¤í…œ í•„ìš” (v4.1+)
- Action: Skip implementation, document in roadmap

**2. Streaming Output**
- Reason: UX improvement, not core functionality
- Action: Defer to v4.1

**3. Caching System**
- Reason: Optimization, not essential for MVP
- Action: Defer to v4.2

**4. 4+ Agent Support**
- Reason: Complexity explosion
- Action: Stick with Main Claude + Codex

**5. Signal-Based Auto-Extension (Q3)**
- Reason: Signal system not validated yet
- Action: Use user-triggered extension for v4.0, defer auto to v4.2

---

## 5. Risk Mitigation

### R1: Time Budget Overflow (>90s avg)

**Risk**: Normal path takes >90s consistently

**Mitigation**:
- âœ… Unanimous check (fast path): saves 30-50s
- âœ… Parallel execution (Phase 3, 4): saves 15-25s
- âœ… User can skip Phase 5: saves 10-30s
- âš ï¸ Monitor: If avg >90s, add "quick mode" flag

**Threshold**: If 5 test runs avg >95s, implement quick mode immediately

---

### R2: Unproductive Back-and-Forth

**Risk**: Agents engage in meaningless rebuttal

**Mitigation**:
- âœ… Enforce "âœ… Acknowledge strengths" first
- âœ… Cap at 3 rounds (4 with user deep dive)
- âœ… Require evidence for continued disagreement
- âœ… User can terminate early (Phase 5 "Conclude")

**Detection**: If challenges lack substance (too generic), refine templates

---

### R3: WebSearch Quality

**Risk**: WebSearch returns irrelevant data

**Mitigation**:
- âœ… Use top 3 results (not just 1)
- âœ… Agents must cite sources (transparency)
- âœ… Fallback: "Evidence not found, proceeding with analysis"
- âœ… User can challenge evidence in Phase 5

**Improvement path**: v4.1 adds source whitelisting

---

## 6. Success Criteria

### Must-Have (v4.0 Release Blockers)

- [ ] **P0**: All 6 phases implemented and tested
- [ ] **P0**: Unanimous check works (self-review + auto-skip)
- [ ] **P0**: User intervention point functional (3 options)
- [ ] **P0**: WebSearch integration works
- [ ] **P0**: Performance: Normal path <90s (avg of 5 runs)
- [ ] **P0**: No breaking changes to v3.1 (backward compatible)

### Nice-to-Have (Can defer)

- [ ] **P1**: Quick mode flag (`--quick`)
- [ ] **P1**: Progress indicators ("Round 2/3...")
- [ ] **P2**: Streaming output
- [ ] **P2**: Caching system

---

## 7. Post-Launch Plan (v4.1-4.2)

### v4.1 (2-3 weeks after v4.0)

**Features**:
1. âœ… Devil's Advocate Mode (hybrid: auto + manual)
2. âœ… Quick Mode flag (`AI í† ë¡  --quick`)
3. âœ… WebSearch source whitelisting
4. âœ… Progress indicators

**Time**: 8-10 hours

---

### v4.2 (1-2 months after v4.0)

**Features**:
1. âœ… Caching system (Codex response + WebSearch)
2. âœ… Signal-based auto-extension (Q3 Codex approach)
3. âœ… Confidence/uncertainty signal system
4. âœ… Performance optimization (target: <60s avg)

**Time**: 10-15 hours

---

## 8. Implementation Checklist

### Pre-Implementation
- [x] Design document approved
- [x] Codex debate completed (ë¯¸í•´ê²° ì§ˆë¬¸ í•´ê²°)
- [x] Implementation plan finalized
- [ ] User confirms: "Start implementation"

### Week 1
- [ ] Day 1-2: Phase 3 implemented
- [ ] Day 2-3: Phase 4 implemented
- [ ] Phase 3-4 tests passing

### Week 2
- [ ] Day 4-5: Phase 5 implemented
- [ ] Day 5-6: Phase 2.3 + Phase 6 updated
- [ ] Day 6-7: E2E tests + edge cases
- [ ] Performance validated (<90s avg)

### Deployment
- [ ] Git commit
- [ ] `/apply-settings`
- [ ] Test in separate project
- [ ] CHANGELOG.md updated
- [ ] User acceptance test

---

## 9. Quick Reference

### Key Files to Modify

```
.claude/skills/ai-collaborative-solver-v2.0/
â”œâ”€â”€ skill.md                    # MAIN FILE (add Phase 3-5, update 2, 6)
â””â”€â”€ scripts/
    â””â”€â”€ codex-session.sh        # Already exists, use as-is
```

### Estimated Lines of Code

| File | Current | Added | Final |
|------|---------|-------|-------|
| skill.md | ~600 lines | +400 lines | ~1000 lines |
| (No new scripts needed) | - | - | - |

### Key Templates to Create

1. Phase 3 Challenge Template (âœ…âš ï¸âŒğŸ“Š)
2. Phase 4 Response Template (with evidence)
3. Phase 5 Summary Template (debate progress)
4. Phase 2.3 Self-Review Prompt (20 words)
5. Phase 6 Multi-Round Synthesis Template

---

## 10. Communication Plan

### User Updates

**After Week 1**:
- âœ… "Phase 3-4 implemented, testing in progress"
- ğŸ“Š Performance preview: "[X]s avg for normal path"

**After Week 2**:
- âœ… "v4.0 complete, ready for deployment"
- ğŸ“Š Final performance: "[X]s fast path, [Y]s normal, [Z]s deep dive"
- ğŸ“‹ "Test in your project before global deployment?"

**Post-Deployment**:
- âœ… "v4.0 deployed globally"
- ğŸ“– "User guide: [link]"
- ğŸ› "Report issues: [how]"

---

## 11. Rollback Plan

**If v4.0 has critical issues**:

```bash
# Revert to v3.1
git revert [v4.0-commit-hash]
/apply-settings

# Or: Keep both versions
# v3.1: Trigger with "AI í† ë¡  v3"
# v4.0: Trigger with "AI í† ë¡  v4" or "AI í† ë¡  --progressive"
```

**Rollback criteria**:
- Performance >120s consistently
- >50% user complaints
- Breaking existing functionality

---

## 12. Summary: What to Do Next

### Immediate Next Step

**Option 1: Start Implementation Now**
```bash
# Begin Week 1, Day 1 tasks
cd .claude/skills/ai-collaborative-solver-v2.0
# Edit skill.md: Add Phase 3 section
```

**Option 2: Create Issue Tracker**
```bash
# If using Linear/GitHub issues
# Create 10 issues for Week 1-2 tasks
# Assign priorities and estimates
```

**Option 3: Prototype First**
```bash
# Quick proof-of-concept
# Test Phase 3 with mock data (no API calls)
cd tmp/
bash prototype-phase3.sh
```

**Recommendation**: **Option 1** - Direct implementation (ì„¤ê³„ ì™„ë£Œë¨)

---

## Document Metadata

**Based on**:
- Design doc: `docs/roadmap/ai-debate-v4-progressive-design.md`
- Codex debate: Completed 2025-11-04
- User requirements: From `/clarify` session

**Approval Status**: â³ Pending user confirmation

**Ready to Start**: âœ… Yes (ëª¨ë“  ê²°ì • ì™„ë£Œ)

---

**Next Action**: ì‚¬ìš©ì í™•ì¸ í›„ Week 1 Day 1 ì‘ì—… ì‹œì‘

**Question for User**:
```
ì§€ê¸ˆ ë°”ë¡œ êµ¬í˜„ ì‹œì‘í• ê¹Œìš”?
1. ì˜ˆ â†’ Week 1 Day 1 (Phase 3) ì‹œì‘
2. ì•„ë‹ˆì˜¤ â†’ ì¶”ê°€ ê²€í† í•  ë¶€ë¶„ì´ ìˆë‚˜ìš”?
3. í”„ë¡œí† íƒ€ì… ë¨¼ì € â†’ tmp/ì— ê°„ë‹¨í•œ POC ì‘ì„±
```
