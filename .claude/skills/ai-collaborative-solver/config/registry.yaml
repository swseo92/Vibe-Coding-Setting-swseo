# AI Model Capability Registry
# Defines available models, their capabilities, and costs

models:
  # OpenAI Codex (GPT-5-Codex)
  - id: openai.codex
    name: "OpenAI Codex (GPT-5-Codex)"
    provider: openai
    adapter: codex
    cli_command: codex
    model: gpt-5-codex
    modalities:
      - text
    context_window: 128000
    max_output_tokens: 4096
    cost:
      prompt_per_1k: 0.005      # $0.005 per 1k tokens
      completion_per_1k: 0.015  # $0.015 per 1k tokens
    capabilities:
      - chat
      - json
      - tool
      - debate
      - code_execution
      - thread_continuity
    features:
      - code_analysis
      - architecture_design
      - bug_investigation
      - security_audit
      - performance_optimization
    quality_tier: premium
    default_playbook_roles:
      clarification: false       # Use cheaper model for clarification
      draft_generation: true     # Primary strength
      quality_gate: true         # Good at evaluation
      escalation: true           # Strong at refinement
    rate_limits:
      requests_per_minute: 60
      requests_per_day: unlimited  # With ChatGPT Plus subscription
    requirements:
      - "ChatGPT Plus subscription ($20/month)"
      - "npm package: @openai/codex"
    status: stable

  # Anthropic Claude (via Claude Code)
  - id: anthropic.claude-sonnet
    name: "Claude Sonnet 4.5"
    provider: anthropic
    adapter: claude
    cli_command: claude        # Claude Code CLI
    model: claude-sonnet-4-5-20250929
    modalities:
      - text
      - image                  # Can read images
    context_window: 200000     # 200k tokens
    max_output_tokens: 8192
    cost:
      prompt_per_1k: 0.003     # $3 per million tokens
      completion_per_1k: 0.015 # $15 per million tokens
    capabilities:
      - chat
      - json
      - tool
      - debate
      - long_context           # 200k context
    features:
      - code_analysis
      - architecture_design
      - reasoning
      - writing
      - analysis
    quality_tier: premium
    default_playbook_roles:
      clarification: true      # Good at questions
      draft_generation: true   # Strong general capability
      quality_gate: true       # Excellent at evaluation
      escalation: true         # Great at refinement
    rate_limits:
      requests_per_minute: 50
      requests_per_day: unlimited  # With subscription
    requirements:
      - "Claude Code CLI (installed and authenticated)"
      - "Run 'claude' to login with Claude account"
      - "Claude Pro/Max subscription recommended"
    status: stable
    notes: "Uses Claude Code CLI login - best coding model in the world (Sep 2025)"

  # Google Gemini 2.5 Pro
  - id: google.gemini-pro
    name: "Gemini 2.5 Pro"
    provider: google
    adapter: gemini
    cli_command: gemini-cli
    modalities:
      - text
      - image
      - video                  # Unique to Gemini
    context_window: 1000000    # 1M tokens!
    max_output_tokens: 8192
    cost:
      prompt_per_1k: 0.001     # $0.001 per 1k tokens (cheap!)
      completion_per_1k: 0.005 # $0.005 per 1k tokens
      free_tier: true          # FREE tier available
    capabilities:
      - chat
      - json
      - debate
      - grounding              # Google Search integration
      - large_context          # 1M tokens
    features:
      - current_information    # Via Google Search
      - trends_analysis
      - research
      - comparison
      - general_qa
    quality_tier: standard
    default_playbook_roles:
      clarification: true      # Cheap, good for questions
      draft_generation: true   # Capable, especially with search
      quality_gate: false      # Less precise than Codex/Claude
      escalation: false        # Better as primary, not escalation
    rate_limits:
      requests_per_minute: 60
      requests_per_day: 1000   # Free tier
    requirements:
      - "Google account (free)"
      - "npm package: @google/gemini-cli"
    status: stable
    free_tier_limits:
      requests_per_minute: 60
      requests_per_day: 1000

# Model Selection Heuristics
# Used by auto-selector to choose best model for problem type

selection_rules:
  - pattern: "code|리뷰|review|bug|버그|refactor|리팩토링"
    category: code_analysis
    recommended_model: openai.codex
    alternatives:
      - anthropic.claude-sonnet
    reason: "Code analysis requires deep technical understanding"

  - pattern: "2025|2024|latest|최신|trend|트렌드|current|현재"
    category: current_information
    recommended_model: google.gemini-pro
    alternatives: []
    reason: "Gemini has Google Search for latest information"

  - pattern: "architecture|아키텍처|design|설계|system|시스템"
    category: architecture
    recommended_model: openai.codex
    alternatives:
      - anthropic.claude-sonnet
    reason: "Architecture requires deep technical reasoning"

  - pattern: "search|검색|research|조사|find|찾기"
    category: research
    recommended_model: google.gemini-pro
    alternatives: []
    reason: "Gemini has Google Search grounding"

  - pattern: "vs|versus|compare|비교|선택|choose"
    category: comparison
    recommended_model: google.gemini-pro
    alternatives:
      - anthropic.claude-sonnet
    reason: "Comparisons benefit from current information"

  - pattern: "security|보안|vulnerability|취약|attack|공격"
    category: security
    recommended_model: openai.codex
    alternatives:
      - anthropic.claude-sonnet
    reason: "Security requires precise code analysis"

  - pattern: "performance|성능|optimize|최적화|speed|속도"
    category: performance
    recommended_model: openai.codex
    alternatives:
      - anthropic.claude-sonnet
    reason: "Performance optimization requires code expertise"

# Fallback Strategy
# When primary model fails or unavailable

fallback_chains:
  openai.codex:
    - anthropic.claude-sonnet  # Similar quality tier
    - google.gemini-pro        # Cost fallback

  anthropic.claude-sonnet:
    - openai.codex             # Similar quality
    - google.gemini-pro        # Cost fallback

  google.gemini-pro:
    - anthropic.claude-sonnet  # Quality upgrade
    - openai.codex             # Quality upgrade

# Cost Optimization Presets
# Recommended model combinations for different budgets

cost_presets:
  minimal:
    description: "Minimize cost (use free tier when possible)"
    clarification: google.gemini-pro
    draft_generation: google.gemini-pro
    quality_gate: google.gemini-pro
    escalation: google.gemini-pro
    estimated_cost_per_debate: 0.00  # Free tier

  balanced:
    description: "Balance cost and quality (recommended)"
    clarification: google.gemini-pro      # Cheap
    draft_generation: anthropic.claude-sonnet  # Quality
    quality_gate: anthropic.claude-sonnet
    escalation: openai.codex              # Best for refinement
    estimated_cost_per_debate: 0.08

  premium:
    description: "Maximum quality (all premium models)"
    clarification: anthropic.claude-sonnet
    draft_generation: openai.codex
    quality_gate: openai.codex
    escalation: anthropic.claude-sonnet  # Different perspective
    estimated_cost_per_debate: 0.15

  hybrid:
    description: "Use multiple models for comparison"
    primary_models:
      - openai.codex
      - anthropic.claude-sonnet
    synthesis_model: anthropic.claude-sonnet
    estimated_cost_per_debate: 0.25

# Model Compatibility Matrix
# Which models work well together in hybrid mode

hybrid_compatibility:
  - models: [openai.codex, anthropic.claude-sonnet]
    synergy: excellent
    reason: "Different architectures, complementary strengths"

  - models: [openai.codex, google.gemini-pro]
    synergy: good
    reason: "Technical depth + current information"

  - models: [anthropic.claude-sonnet, google.gemini-pro]
    synergy: good
    reason: "Reasoning + search grounding"

  - models: [openai.codex, anthropic.claude-sonnet, google.gemini-pro]
    synergy: excellent
    reason: "Three different perspectives, comprehensive coverage"
